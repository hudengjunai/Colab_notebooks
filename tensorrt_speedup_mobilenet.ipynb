{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hudengjunai/Colab_notebooks/blob/master/tensorrt_speedup_mobilenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6xMhI4Xb7G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOvK5KaH9cCT",
        "colab_type": "text"
      },
      "source": [
        "#  so the conclusion is tensorrt will speedup 2x in mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IftJy0PcA3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.contrib.tensorrt as trt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK4pX8OIcQWT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --quiet https://raw.githubusercontent.com/Tony607/tf_jetson_nano/master/data/elephant.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuXOay41cVIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8f9330b-f45e-4f01-f924-f3b6ec1483dd"
      },
      "source": [
        "!ls #sample_data/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "elephant.jpg  model  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnqTzxuicWQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 as Net\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input,decode_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhsmNV_7c2MN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "img_path = './elephant.jpg'\n",
        "model_path = './model'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSC8HEfUdOEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0663b388-3be0-4a9c-d235-a73fcf021f1f"
      },
      "source": [
        "if not os.path.exists(model_path):\n",
        "  os.mkdir(model_path)\n",
        "  \n",
        "model_fname = os.path.join(model_path,'model.h5')\n",
        "\n",
        "os.makedirs(model_path,exist_ok=True)\n",
        "\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "model = Net(weights='imagenet')\n",
        "\n",
        "img = image.load_img(img_path,target_size=(img_height,img_width))\n",
        "x =image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "preds = model.predict(x)\n",
        "\n",
        "print(\"predicted si \",decode_predictions(preds,top=3)[0])\n",
        "\n",
        "model.save(model_fname)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted si  [('n02504458', 'African_elephant', 0.705134), ('n01871265', 'tusker', 0.1551433), ('n02504013', 'Indian_elephant', 0.039011613)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz9XVdRed-MF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2d8c00b-074b-47d3-b2b7-cceb2ae484f1"
      },
      "source": [
        "## Benckmark keras prediction speed\n",
        "import time\n",
        "times= []\n",
        "for i in range(30):\n",
        "  start_time =time.time()\n",
        "  preds = model.predict(x)\n",
        "  delta = time.time() - start_time\n",
        "  times.append(delta)\n",
        "  \n",
        "  \n",
        "mean_delta = np.array(times).mean()\n",
        "fps = 1/mean_delta\n",
        "print(\"average(sec):{0},fps:{1}\".format(mean_delta,fps))\n",
        "\n",
        "tf.keras.backend.clear_session()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average(sec):0.021813845634460448,fps:45.84244414108482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLazGCZMevn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "395a8c36-c970-4397-9ac2-9c69d2fb2616"
      },
      "source": [
        "!ls model\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEhI7LsVe3A8",
        "colab_type": "text"
      },
      "source": [
        "## Freeze graph and export .pb file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abqwhST1e9As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import graph_io\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "tf.keras.backend.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF19aPgM0oxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_pb_dir = './model'\n",
        "model_name = './model/model.h5'\n",
        "\n",
        "def freeze_graph(graph,\\\n",
        "                 session,\\\n",
        "                 output,\\\n",
        "                 save_pb_dir='.',\\\n",
        "                 save_pb_name='frozon_model.pb',\\\n",
        "                 save_pb_as_text=False):\n",
        "  with graph.as_default():\n",
        "    #get the inference graph\n",
        "    graphdef_inf = tf.graph_util.remove_training_nodes(graph.as_graph_def())\n",
        "    graphdef_frozen = tf.graph_util.convert_variables_to_constants(session,graphdef_inf,output)\n",
        "    graph_io.write_graph(graphdef_frozen,save_pb_dir,save_pb_name,as_text=save_pb_as_text)\n",
        "    return graphdef_frozen\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWuvE2pz1kZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "81ec526b-a5cb-41e9-f01f-ab448bd69e5e"
      },
      "source": [
        "tf.keras.backend.set_learning_phase(0)\n",
        "\n",
        "model = load_model(model_fname)\n",
        "\n",
        "session = tf.keras.backend.get_session()\n",
        "\n",
        "input_names = [t.op.name for t in model.inputs]\n",
        "output_names = [t.op.name for t in model.outputs]\n",
        "\n",
        "print(\"input names \\n\",input_names)\n",
        "print(\"output names \\n\",output_names)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0815 05:55:20.357565 140715131443072 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0815 05:55:20.362101 140715131443072 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0815 05:55:20.367070 140715131443072 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0815 05:55:26.430861 140715131443072 hdf5_format.py:221] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "input names \n",
            " ['input_1']\n",
            "output names \n",
            " ['Logits/Softmax']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7cozSnq1_mL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.set_learning_phase?\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpzRLy6K2McF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frozen_graph = freeze_graph(session.graph,session,\\\n",
        "                            [out.op.name for out in model.outputs],\\\n",
        "                            save_pb_dir=save_pb_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeUsmoo02hl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import tensorflow.contrib.tensorrt as trt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNXkkzv24K7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Optimize with TensorRt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKUVzVW84moJ",
        "colab_type": "text"
      },
      "source": [
        "### Optimize with TensorRt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VOSHWZq4tDH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7994baeb-b622-455a-c7b3-474748ff1a24"
      },
      "source": [
        "trt_graph = trt.create_inference_graph(input_graph_def = frozen_graph,\\\n",
        "                                      outputs = output_names,\\\n",
        "                                      max_batch_size = 1,\\\n",
        "                                      max_workspace_size_bytes = 1 << 25,\\\n",
        "                                      minimum_segment_size = 50)\n",
        "graph_io.write_graph(trt_graph,'./model','trt_graph.pb',as_text=False)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./model/trt_graph.pb'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXsbd-zb5NPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39e13bb8-86ee-4180-b876-1647fbf7ab0b"
      },
      "source": [
        "!ls model"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frozon_model.pb  model.h5  trt_graph.pb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EQ1-lLE5d3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "def get_frozen_graph(graph_file):\n",
        "  with tf.gfile.FastGFile(graph_file,'rb') as f:\n",
        "    graphdef = tf.GraphDef()\n",
        "    graphdef.ParseFromString(f.read())\n",
        "    return graphdef\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6OY495Q6LdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graphdef = get_frozen_graph('./model/trt_graph.pb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0SDILk_6SmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "tf.import_graph_def(graphdef,name='')\n",
        "graph = tf.get_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2oWu1oz6kMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_node = graph.get_tensor_by_name('input_1:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w40ZS1q26rmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_node = graph.get_tensor_by_name('Logits/Softmax:0')#len(graphdef.node)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwnEtN326xVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = './elephant.jpg'\n",
        "img = image.load_img(img_path,target_size=[224,224])\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "x = preprocess_input(x)\n",
        "\n",
        "feed_dict = {input_node:x}\n",
        "preds = sess.run(output_node,feed_dict=feed_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkUt6UQl7K2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "784c8258-4ef0-470c-d331-261935eb5756"
      },
      "source": [
        "times = []\n",
        "for i in range(30):\n",
        "  start_time = time.time()\n",
        "  preds = sess.run(output_node,feed_dict=feed_dict)\n",
        "  delta = time.time() - start_time\n",
        "  times.append(delta)\n",
        "mean_time = np.array(times).mean()\n",
        "fps = 1/mean_time\n",
        "print(\"mean time used is {0},fps:{1} \".format(mean_time,fps))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean time used is 0.010166740417480469,fps:98.359942217136 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQI8sKY88kSR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# so the conclusion is tensorrt will speedup 2x in mobilenet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kbt2EgW9Yrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}